{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1e77uMUqNTEALU0n0Nj-007eQe_w039CR","timestamp":1684356378561}],"authorship_tag":"ABX9TyNVS5lrDkd2IFxR4n+/6hhW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDIDQCIbl9z5","executionInfo":{"status":"ok","timestamp":1684356359100,"user_tz":-330,"elapsed":66788,"user":{"displayName":"samridh deva","userId":"03768848826490263438"}},"outputId":"006bfddd-df1c-4b45-e293-2c6a1fa5d71e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scraped 4 links from 0 to 99\n","Scraped 0 links from 100 to 199\n","Scraped 1 links from 200 to 299\n","Scraped 0 links from 300 to 399\n","Scraped 0 links from 400 to 499\n","Scraped 0 links from 500 to 599\n","Scraped 0 links from 600 to 699\n","Scraped 0 links from 700 to 799\n","Scraped 0 links from 800 to 899\n","Scraped 0 links from 900 to 999\n","Scraped 0 links from 1000 to 1099\n","Scraped 0 links from 1100 to 1199\n","Scraped 0 links from 1200 to 1299\n","Scraped 0 links from 1300 to 1399\n","Scraped 0 links from 1400 to 1499\n","Scraped 0 links from 1500 to 1599\n","Scraped 0 links from 1600 to 1699\n","Scraped 0 links from 1700 to 1799\n","Scraped 0 links from 1800 to 1899\n","Scraped 0 links from 1900 to 1999\n","Scraped 0 links from 2000 to 2099\n","Scraped 0 links from 2100 to 2199\n","Scraped 0 links from 2200 to 2299\n","Scraped 0 links from 2300 to 2399\n","Scraped 0 links from 2400 to 2499\n","Scraped 0 links from 2500 to 2599\n","Scraped 0 links from 2600 to 2699\n","Scraped 0 links from 2700 to 2799\n","Scraped 0 links from 2800 to 2899\n","Scraped 0 links from 2900 to 2999\n","Scraped 0 links from 3000 to 3099\n","Scraped 0 links from 3100 to 3199\n","Scraped 0 links from 3200 to 3299\n","Scraped 0 links from 3300 to 3399\n","Scraped 0 links from 3400 to 3499\n","Scraped 0 links from 3500 to 3599\n","Scraped 0 links from 3600 to 3699\n","Scraped 0 links from 3700 to 3799\n","Scraped 0 links from 3800 to 3899\n","Scraped 0 links from 3900 to 3999\n","Scraped 0 links from 4000 to 4099\n","Scraped 0 links from 4100 to 4199\n","Scraped 0 links from 4200 to 4299\n","Scraped 0 links from 4300 to 4399\n","Scraped 0 links from 4400 to 4499\n","Scraped 0 links from 4500 to 4599\n","Scraped 0 links from 4600 to 4699\n","Error: 429\n","Total number of unique links: 4\n","Saved results in JSON format\n","Saved results in CSV format\n"]}],"source":["import requests\n","import re\n","import json\n","import csv\n","\n","\n","google_url = \"https://www.google.com/search\"\n","search_query = \"site:youtube.com openinapp.co\"\n","num_results = 10000\n","start_index = 0\n","\n","youtube_links = []\n","\n","while start_index < num_results:\n","    params = {\"q\": search_query, \"num\": 100, \"start\": start_index}\n","    response = requests.get(google_url, params=params)\n","    if response.status_code == 200:\n","        html = response.text\n","        links = re.findall(r'https:\\/\\/www\\.youtube\\.com\\/(?:channel\\/[\\w-]+|c\\/[\\w-]+|user\\/[\\w-]+)', html)\n","        youtube_links.extend(links)\n","        print(f\"Scraped {len(links)} links from {start_index} to {start_index + 99}\")\n","        start_index += 100\n","    else:\n","        print(f\"Error: {response.status_code}\")\n","        break\n","\n","youtube_links = list(dict.fromkeys(youtube_links))\n","print(f\"Total number of unique links: {len(youtube_links)}\")\n","\n","with open(\"youtube_links.json\", \"w\") as json_file:\n","    json.dump(youtube_links, json_file)\n","    print(\"Saved results in JSON format\")\n","\n","with open(\"youtube_links.csv\", \"w\") as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    csv_writer.writerow(['Youtube Links'])\n","    for link in youtube_links:\n","        formula = f'=HYPERLINK(\"{link}\",\"{link}\")'\n","        csv_writer.writerow([formula])\n","    print(\"Saved results in CSV format\")\n"]}]}